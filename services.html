<!DOCTYPE html>
<html lang="en">
<head>
<link rel="stylesheet" type="text/css" href="styles/style.css">
<title>OpenFAM: A library for programming Fabric-Attached Memory</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<body>
	<header>
		<h1>OpenFAM Reference Implementation</h1>
	</header>
	<section>
		<nav>
			<ul>
				<li><a href="index.html">Home</a></li>
				<li><a href="limitations.html">Design Choices</a></li>
				<li><a href="errors.html">Exceptions and Error Codes</a></li>
				<li><a href="services.html">Services</a></li>
				<li><a href="config_files.html">Configuration Files</a></li>
			</ul>
			<hr>
			Initialization and Finalization
			<ul>
				<li><a href="fam_initialize.html">fam_initialize</a></li>
				<li><a href="fam_finalize.html">fam_finalize</a></li>
				<li><a href="fam_abort.html">fam_abort</a></li>
			</ul>
			<hr>
			Options &amp; Query
			<ul>
				<li><a href="fam_list_options.html">fam_list_options</a></li>
				<li><a href="fam_get_option.html">fam_get_option</a></li>
				<li><a href="fam_lookup.html">fam_lookup</a></li>
				<li><a href="fam_stat.html">fam_stat</a></li>
			</ul>
			<hr>
			Memory Allocation
			<ul>
				<li><a href="fam_create_region.html">fam_create_region</a></li>
				<li><a href="fam_destroy_region.html">fam_destroy_region</a></li>
				<li><a href="fam_resize_region.html">fam_resize_region</a></li>
				<li><a href="fam_allocate.html">fam_allocate</a></li>
				<li><a href="fam_deallocate.html">fam_deallocate</a></li>
				<li><a href="fam_change_permissions.html">fam_change_permissions</a></li>
			</ul>
			<hr>
			Memory Map
			<ul>
				<li><a href="fam_map.html">fam_map</a></li>
				<li><a href="fam_unmap.html">fam_unmap</a></li>
			</ul>
			<hr>
			Data Path Operations
			<ul>
				<li><a href="fam_get.html">fam_get</a></li>
				<li><a href="fam_put.html">fam_put</a></li>
				<li><a href="fam_gather.html">fam_gather</a></li>
				<li><a href="fam_scatter.html">fam_scatter</a></li>
				<li><a href="fam_copy.html">fam_copy</a></li>
				<li><a href="fam_copy_wait.html">fam_copy_wait</a></li>
			</ul>
			<hr>
			Atomics
			<ul>
				<li><a href="fam_set.html">fam_set</a></li>
				<li><a href="fam_add.html">fam_add</a></li>
				<li><a href="fam_subtract.html">fam_subtract</a></li>
				<li><a href="fam_min.html">fam_min</a></li>
				<li><a href="fam_max.html">fam_max</a></li>
				<li><a href="fam_and.html">fam_and</a></li>
				<li><a href="fam_or.html">fam_or</a></li>
				<li><a href="fam_xor.html">fam_xor</a></li>
				<li><a href="fam_fetch_TYPE.html">fam_fetch_TYPE</a></li>
				<li><a href="fam_swap.html">fam_swap</a></li>
				<li><a href="fam_compare_swap.html">fam_compare_swap</a></li>
				<li><a href="fam_fetch_add.html">fam_fetch_add</a></li>
				<li><a href="fam_fetch_subtract.html">fam_fetch_subtract</a></li>
				<li><a href="fam_fetch_min.html">fam_fetch_min</a></li>
				<li><a href="fam_fetch_and.html">fam_fetch_and</a></li>
				<li><a href="fam_fetch_max.html">fam_fetch_max</a></li>
				<li><a href="fam_fetch_or.html">fam_fetch_or</a></li>
				<li><a href="fam_fetch_xor.html">fam_fetch_xor</a></li>
			</ul>
			<hr>
			Ordering
			<ul>
				<li><a href="fam_barrier_all.html">fam_barrier_all</a></li>
				<li><a href="fam_fence.html">fam_fence</a></li>
				<li><a href="fam_quiet.html">fam_quiet</a></li>
			</ul>
			<hr>
		</nav>
		<article>
		<h1>OpenFAM 2.0 Services</h1>
<p> The initial reference implementation of OpenFAM was built using a single memory server.
 As expected, the memory server becomes a bottleneck even for a small number of concurrent PEs.
For OpenFAM version 2.0, we have made significant changes to the design of the memory server,
with these high level requirements.

<ul>
<li>Support for larger pool of memory by scaling to multiple memory servers.
Support larger region sizes that exceed the size of a single node thereby making large pool of
memory accessible to the application.</li>
<li>Because regions are intended to be large containers for data items, to improve data path performance,
we need to allow the same region to encompass multiple memory nodes. This would reduce both network bottlenecks
at the network interfaces, as well as performance bottlenecks due to limited compute capacity at a given memory server.</li>
<li>We need to consider dynamic addition of memory servers when additional memory is required, without
disturbing previously allocated memory.</li>
</ul>
<figure>
<img src="images/openfam2.0memoryserver.png" width="450px">
<figcaption>Figure 1: OpenFAM 2.0 Memory server components</figcaption>
</figure>
<p> There are three main components in the design.
<ol>
<li>The client interface service (CIS): All the PE’s talk to the CIS for memory server operations.</li>
<li>The metadata management service: Region and data item metadata will be hosted in the metadata management service.
The service could either run in same node as a CIS or a memory server, or it can run in dedicated metadata management nodes.</li>
<li>The memory management service: The actual memory will be served from memory servers.
For data path (get,put and atomic) operations PEs will talk to the memory servers directly.
For memory management and metadata operations, like allocate, lookup, create_region, etc.,
the CIS will communicate with memory servers via an RPC service or via direct functions calls.</li>
</ol>
We have defined an RPC path and a direct path for all the three components – CIS, memory management service and metadata management service.
Yaml based configuration parameters are available to decide how these services are running.  If the components are running as separate services,
a grpc call is made to the service. If the services are running within other component (direct path), a function call is made.
<p> Now let us look at some of the possible combinations.
<ol>
<li>All services running separately:
If all the components are running as separate services, a grpc call will be made to the services.
As shown in Figure 1, PE will make an RPC call to CIS, in-turn CIS will make an RPC call to metadata
management service and memory management service for all memory management and metadata operations.
</li>
<li>CIS running as separate service with other services contained within CIS.
In this case PE will make a grpc call to CIS and CIS makes direct  function call to
other services. Figure 2, shows one such configuration where CIS and metadata running as a single service,
with multiple memory servers connected to it. For memory management and metadata operations all the PE’s
will make call to CIS, and for data path operations PE’s will communicate directly with memory servers.
</li>
</ol>
 <figure>
<img src="images/openfam2.0exampleconfiguration.png" width="450px">
<figcaption>Figure 2: A possible configuration with metadata running as part of CIS</figcaption>
</figure>
<p>See configuration and startup of OpenFAM 2.0 services in this section. <a href="config_files.html">Configuration Files</a></p>
		</article>
	</section>
	<footer>
		<p>Copyright 2021, Hewlett Packard Enterprise Development Co, LLP</p>
	</footer>
</body>
</html>
